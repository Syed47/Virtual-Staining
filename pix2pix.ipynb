{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384f2290-16e6-4bf7-84e8-4130ce626141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n\\n1. Downsample 4 images into 1 - DONE\\n2. Enhance florescent images (intensity & color) - DONE\\n3. Build and train Pix2Pix model - DONE\\n4. Figure out what the best distance is for virtual staining\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "1. Downsample 4 images into 1 - DONE\n",
    "2. Enhance florescent images (intensity & color) - DONE\n",
    "3. Build and train Pix2Pix model - DONE\n",
    "4. Figure out what the best distance is for virtual staining\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ace080-7f20-40d5-a522-7ae9bfe19b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, shutil, random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d52a2bab-3c51-47de-91d9-c46abb502f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluorescence enhanced and images saved.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"datasets\"\n",
    "\n",
    "def enhance_fluorescence(image_path, threshold, color=(0, 255, 0)):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    grayscale = img.convert(\"L\")\n",
    "    img_array = np.array(img)\n",
    "    gray_array = np.array(grayscale)\n",
    "\n",
    "    mask = gray_array > threshold \n",
    "    img_array[mask] = color \n",
    "\n",
    "    enhanced_img = Image.fromarray(img_array)\n",
    "    return enhanced_img\n",
    "\n",
    "for file in os.listdir(dataset_dir):\n",
    "    if file.endswith(\"f.tif\"):\n",
    "        img_path = os.path.join(dataset_dir, file)\n",
    "        enhanced_img = enhance_fluorescence(img_path, threshold=7)\n",
    "        enhanced_img.save(os.path.join(dataset_dir, file))\n",
    "\n",
    "print(\"Fluorescence enhanced and images saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef70ef8-dff7-49ba-a3ec-36fa6e0cc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images paired and saved\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"datasets\"\n",
    "output_dir = \"paired_patches\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def split_image(image_path, patch_size=(512, 512), downsample_size=(256, 256)):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    patches = []\n",
    "    for i in range(0, w, patch_size[0]):\n",
    "        for j in range(0, h, patch_size[1]):\n",
    "            if i + patch_size[0] <= w and j + patch_size[1] <= h:\n",
    "                patch = img.crop((i, j, i + patch_size[0], j + patch_size[1]))\n",
    "                patch = patch.resize(downsample_size, Image.LANCZOS)\n",
    "                patches.append((i, j, patch))\n",
    "    return patches\n",
    "\n",
    "\n",
    "image_files = [f for f in os.listdir(dataset_dir) if f.endswith(\".tif\")]\n",
    "\n",
    "for i in range(0, len(image_files), 12):\n",
    "    batch = image_files[i:i+12]\n",
    "    # input_images = batch[:11] # :11\n",
    "    input_images = [img for img in batch if img.endswith(\"_0.5.tif\")]\n",
    "    output_image = batch[11]\n",
    "    \n",
    "    output_patches = split_image(os.path.join(dataset_dir, output_image))\n",
    "\n",
    "    image_counter = 0\n",
    "    for input_image in input_images:\n",
    "        input_patches = split_image(os.path.join(dataset_dir, input_image))\n",
    "\n",
    "        for idx, (output_patch, input_patch) in enumerate(zip(output_patches, input_patches)):\n",
    "            out_x, out_y, out_patch = output_patch\n",
    "            in_x, in_y, in_patch = input_patch\n",
    "\n",
    "            in_patch = np.array(in_patch) / 127.5 - 1.0\n",
    "            out_patch = np.array(out_patch) / 127.5 - 1.0\n",
    "            \n",
    "            paired_img = Image.new(\"RGB\", (512, 256))\n",
    "            in_patch = Image.fromarray((in_patch * 127.5 + 127.5).astype(np.uint8))\n",
    "            out_patch = Image.fromarray((out_patch * 127.5 + 127.5).astype(np.uint8))\n",
    "            \n",
    "            paired_img.paste(in_patch, (0, 0))\n",
    "            paired_img.paste(out_patch, (256, 0))\n",
    "\n",
    "            patch_filename = f\"{input_image[8:]}_{image_counter}.png\"\n",
    "            image_counter += 1\n",
    "\n",
    "            paired_img.save(os.path.join(output_dir, patch_filename))\n",
    "\n",
    "print(\"Images paired and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b21cdba6-5937-4672-92d8-861cd32f72ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 34 images, Validation set: 6 images.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir, train_dir, val_dir = \"paired_patches\", \"paired_patches/train\", \"paired_patches/test\"\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(dataset_dir) if f.endswith(\".png\")]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "train_size = int(0.85 * len(image_files))\n",
    "for f in image_files[:train_size]: shutil.move(os.path.join(dataset_dir, f), os.path.join(train_dir, f))\n",
    "for f in image_files[train_size:]: shutil.move(os.path.join(dataset_dir, f), os.path.join(val_dir, f))\n",
    "\n",
    "print(f\"Training set: {len(image_files[:train_size])} images, Validation set: {len(image_files[train_size:])} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97705705-604a-4df4-98ca-ba93ca799531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

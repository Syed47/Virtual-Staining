{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384f2290-16e6-4bf7-84e8-4130ce626141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n\\n1. Downsample 4 images into 1 - DONE\\n2. Enhance florescent images (intensity & color) - DONE\\n3. Build and train Pix2Pix model - DONE\\n4. Figure out what the best distance is for virtual staining\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "\n",
    "1. Downsample 4 images into 1 - DONE\n",
    "2. Enhance florescent images (intensity & color) - DONE\n",
    "3. Build and train Pix2Pix model - DONE\n",
    "4. Figure out what the best distance is for virtual staining\n",
    "5. Improve marking centre of cells\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7ace080-7f20-40d5-a522-7ae9bfe19b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os, shutil, random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "import multiprocessing\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6be6dfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset of data created with 164 PNG images\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"dataset-OVCAR/dataset\"\n",
    "subset_dir = \"datasets\"\n",
    "os.makedirs(subset_dir, exist_ok=True)\n",
    "\n",
    "subset = 4 # Image to filter from, 0 <= subset <= 300\n",
    "filter_level = 0\n",
    "\n",
    "def clip_and_convert_to_png(file):\n",
    "    img_path = os.path.join(dataset_dir, file)\n",
    "    new_file_name = os.path.splitext(file)[0] + \".png\"\n",
    "    new_path = os.path.join(subset_dir, new_file_name)\n",
    "    \n",
    "    try:\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size  \n",
    "            l, t = (width - 1024) // 2, (height - 1024) // 2\n",
    "            r, b = l + 1024, t + 1024\n",
    "            cropped_img = img.crop((l, t, r, b))\n",
    "            cropped_img.save(new_path, format=\"PNG\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "files = [\n",
    "    f for f in os.listdir(dataset_dir) if f.endswith((f\"{filter_level}.tif\", \"f.tif\"))\n",
    "]#[:subset]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "    executor.map(clip_and_convert_to_png, files)\n",
    "\n",
    "print(f\"Subset of data created with {len(files)} PNG images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbe28099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fluorescence enhanced and images saved.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = subset_dir\n",
    "\n",
    "def enhance_fluorescence(image_path, threshold, color=(0, 255, 0)):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    grayscale = img.convert(\"L\")\n",
    "    img_array = np.array(img)\n",
    "    gray_array = np.array(grayscale)\n",
    "\n",
    "    mask = gray_array > threshold \n",
    "    img_array[mask] = color \n",
    "\n",
    "    enhanced_img = Image.fromarray(img_array)\n",
    "    return enhanced_img\n",
    "\n",
    "for file in os.listdir(dataset_dir):\n",
    "    if file.endswith(\"f.png\"):\n",
    "        img_path = os.path.join(dataset_dir, file)\n",
    "        enhanced_img = enhance_fluorescence(img_path, threshold=8)\n",
    "        enhanced_img.save(os.path.join(dataset_dir, file))\n",
    "\n",
    "print(\"Fluorescence enhanced and images saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e890726c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation Done!\n",
      "Original Images: 164\n",
      "Augmented Images: 656\n"
     ]
    }
   ],
   "source": [
    "def rotate_and_zoom_pair(image_path, output_path, angle=90):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = image.rotate(angle)\n",
    "    image.save(output_path, format=\"PNG\")\n",
    "\n",
    "def increase_brightness_linear(image_path, output_path, min_factor, max_factor):\n",
    "    if not image_path.endswith(\"f.png\"):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "        pixels = np.array(image, dtype=np.float32)\n",
    "        \n",
    "        gradient = np.linspace(min_factor, max_factor, width)\n",
    "        brightness_matrix = np.tile(gradient, (height, 1))[:, :, None]\n",
    "        \n",
    "        brightened_pixels = np.clip(pixels * brightness_matrix, 0, 255).astype(np.uint8)\n",
    "        Image.fromarray(brightened_pixels).save(output_path)\n",
    "    else:\n",
    "        Image.open(image_path).convert(\"RGB\").save(output_path)\n",
    "\n",
    "def increase_brightness_radial(image_path, output_path, min_factor, max_factor):\n",
    "    if not image_path.endswith(\"f.png\"):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        width, height = image.size\n",
    "        pixels = np.array(image, dtype=np.float32)\n",
    "\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        y_indices, x_indices = np.meshgrid(np.arange(height), np.arange(width), indexing=\"ij\")\n",
    "        distances = np.sqrt((x_indices - center_x) ** 2 + (y_indices - center_y) ** 2)\n",
    "\n",
    "        max_distance = np.max(distances)\n",
    "        radial_factor = min_factor + (max_factor - min_factor) * (1 - distances / max_distance)\n",
    "        radial_matrix = np.repeat(radial_factor[:, :, None], 3, axis=2)\n",
    "\n",
    "        brightened_pixels = np.clip(pixels * radial_matrix, 0, 255).astype(np.uint8)\n",
    "        Image.fromarray(brightened_pixels).save(output_path)\n",
    "    else:\n",
    "        Image.open(image_path).convert(\"RGB\").save(output_path)\n",
    "\n",
    "\n",
    "def process_image(file, rotation_angle, brightness_factor=(0.75, 1.25)):\n",
    "    image_path = os.path.join(subset_dir, file)\n",
    "    rotate_and_zoom_pair(image_path, os.path.join(subset_dir, f\"rotate_90_{file}\"), rotation_angle)\n",
    "    rotate_and_zoom_pair(image_path, os.path.join(subset_dir, f\"rotate_180_{file}\"), rotation_angle*2)\n",
    "    rotate_and_zoom_pair(image_path, os.path.join(subset_dir, f\"rotate_270_{file}\"), rotation_angle*3)\n",
    "    # increase_brightness_linear(image_path, os.path.join(subset_dir, f\"linear_{file}\"), \n",
    "                            #    brightness_factor[0], brightness_factor[1])\n",
    "    # increase_brightness_radial(image_path, os.path.join(subset_dir, f\"radial_{file}\"), \n",
    "                            #    brightness_factor[0], brightness_factor[1])\n",
    "\n",
    "images = [f for f in os.listdir(subset_dir) if f.endswith(\".png\")]\n",
    "original_size = len(os.listdir(subset_dir))\n",
    "\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:\n",
    "    for i, img in enumerate(images):\n",
    "        brightness_factor = (np.random.uniform(0.75, 1), np.random.uniform(1, 2))\n",
    "        executor.submit(process_image, img, 90, brightness_factor)\n",
    "\n",
    "print(\"Augmentation Done!\")\n",
    "print(\"Original Images:\", original_size)\n",
    "print(\"Augmented Images:\", len(os.listdir(subset_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5fa0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation test\n",
    "# source = [f for f in os.listdir(\".\") if f.endswith(\".png\")]\n",
    "\n",
    "# print(type(Image.open(\"img1.png\")))\n",
    "\n",
    "\n",
    "# for img in source:\n",
    "#     for i in range(5):\n",
    "#         min_factor, max_factor = np.random.uniform(0.5, 1), np.random.uniform(1, 2)\n",
    "#         print(min_factor, max_factor)\n",
    "#         increase_brightness_linear(img, f\"{img[:-4]}_linear_{i}.png\", min_factor, max_factor)\n",
    "#     for i in range(5):\n",
    "#         min_factor, max_factor = np.random.uniform(0.5, 1), np.random.uniform(1, 2)\n",
    "#         print(min_factor, max_factor)\n",
    "#         increase_brightness_radial(img, f\"{img[:-4]}_radial_{i}.png\", min_factor, max_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ef70ef8-dff7-49ba-a3ec-36fa6e0cc2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n",
      "Images paired and saved\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"virtual_staining_OVCAR\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "filter_level = \"0\"\n",
    "\n",
    "def split_image(image_path, patch_size=(256, 256), downsample_size=(256, 256)):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    w, h = img.size\n",
    "    patches = []\n",
    "    for i in range(0, w, patch_size[0]):\n",
    "        for j in range(0, h, patch_size[1]):\n",
    "            if i + patch_size[0] <= w and j + patch_size[1] <= h:\n",
    "                patch = img.crop((i, j, i + patch_size[0], j + patch_size[1]))\n",
    "                # patch = patch.resize(downsample_size, Image.LANCZOS)\n",
    "                patches.append((i, j, patch))\n",
    "    return patches\n",
    "\n",
    "counter = 0\n",
    "image_files = [f for f in os.listdir(dataset_dir) if f.endswith(\".png\")]\n",
    "print(len(image_files))\n",
    "for i in range(0, len(image_files), 2):\n",
    "    batch = image_files[i:i+2]\n",
    "    # input_images = batch[:11] # :11\n",
    "    input_image = batch[0]#[img for img in batch if not img.endswith(f\"f.png\")]\n",
    "    output_image = batch[1]\n",
    "    output_patches = split_image(os.path.join(dataset_dir, output_image))\n",
    "    input_patches = split_image(os.path.join(dataset_dir, input_image))\n",
    "    image_counter = 0\n",
    "    for idx, (output_patch, input_patch) in enumerate(zip(output_patches, input_patches)):\n",
    "        out_x, out_y, out_patch = output_patch\n",
    "        in_x, in_y, in_patch = input_patch\n",
    "\n",
    "        in_patch = np.array(in_patch) / 127.5 - 1.0\n",
    "        out_patch = np.array(out_patch) / 127.5 - 1.0\n",
    "        \n",
    "        paired_img = Image.new(\"RGB\", (512, 256))\n",
    "        in_patch = Image.fromarray((in_patch * 127.5 + 127.5).astype(np.uint8))\n",
    "        out_patch = Image.fromarray((out_patch * 127.5 + 127.5).astype(np.uint8))\n",
    "        \n",
    "        paired_img.paste(in_patch, (0, 0))\n",
    "        paired_img.paste(out_patch, (256, 0))\n",
    "\n",
    "        patch_filename = f\"{input_image[:-4]}_{image_counter}.png\"\n",
    "        image_counter += 1\n",
    "\n",
    "        paired_img.save(os.path.join(output_dir, patch_filename))\n",
    "\n",
    "print(\"Images paired and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e8c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555 218\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "def valid_image(image_path, target_color=(0, 255, 0)):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    if target_color not in image.getdata():\n",
    "        if np.random.uniform(0, 1) < 0.8:\n",
    "            os.remove(image_path)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "image_files = [f\"{os.path.join(output_dir, f)}\" for f in os.listdir(output_dir) if f.endswith(\".png\")]\n",
    "for f in image_files:\n",
    "    if not valid_image(f):\n",
    "        found += 1\n",
    "\n",
    "print(len(image_files), found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21cdba6-5937-4672-92d8-861cd32f72ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 2669 images, Validation set: 668 images.\n"
     ]
    }
   ],
   "source": [
    "dataset_dir, train_dir, val_dir = output_dir, f\"{output_dir}/train\", f\"{output_dir}/test\"\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(dataset_dir) if f.endswith(\".png\")]\n",
    "random.shuffle(image_files)\n",
    "\n",
    "train_size = int(0.8 * len(image_files))\n",
    "for f in image_files[:train_size]: shutil.move(os.path.join(dataset_dir, f), os.path.join(train_dir, f))\n",
    "for f in image_files[train_size:]: shutil.move(os.path.join(dataset_dir, f), os.path.join(val_dir, f))\n",
    "\n",
    "print(f\"Training set: {len(image_files[:train_size])} images, Validation set: {len(image_files[train_size:])} images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97705705-604a-4df4-98ca-ba93ca799531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test image moved to pix2pix\n"
     ]
    }
   ],
   "source": [
    "# Move train/test data to correct location for pix2pix process\n",
    "# Filter subset of dataset\n",
    "train_test_dir = os.path.join(\"pytorch-CycleGAN-and-pix2pix/datasets\", output_dir)\n",
    "if os.path.exists(train_test_dir):\n",
    "    shutil.rmtree(train_test_dir)\n",
    "\n",
    "shutil.copytree(output_dir, train_test_dir)\n",
    "\n",
    "print(f\"Train/Test image moved to pix2pix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51671fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marking centres of florescent cells\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import center_of_mass, label\n",
    "\n",
    "img = Image.open(\"datasets/rotate_90_capture_19800_750_6742.8_f.png\").convert(\"RGB\")\n",
    "img_np = np.array(img)\n",
    "\n",
    "green_mask = (img_np[:, :, 1] == 255) & (img_np[:, :, 0] == 0) & (img_np[:, :, 2] == 0)\n",
    "binary = green_mask.astype(np.uint8)\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50))\n",
    "binary_cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "labeled_array, num_features = label(binary_cleaned)\n",
    "\n",
    "for i in range(1, num_features + 1):\n",
    "    blob = (labeled_array == i)\n",
    "    target_pixels = np.sum(blob)\n",
    "    if target_pixels > 1000: # filtering bigger bobs only\n",
    "        y, x = center_of_mass(blob)\n",
    "        cv2.circle(img_np, (int(x), int(y)), radius=10, color=(255, 0, 0), thickness=-1)\n",
    "\n",
    "result = Image.fromarray(img_np)\n",
    "result.save(\"separated_cleaned_centers.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
